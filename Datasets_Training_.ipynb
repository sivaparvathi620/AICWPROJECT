{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1HNX01JXlY3OAHEst27ludJK_L1Ex_2ks",
      "authorship_tag": "ABX9TyNTeGAG12D88k++roDCY1p9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sivaparvathi620/AICWPROJECT/blob/main/Datasets_Training_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect The Google Drive"
      ],
      "metadata": {
        "id": "loXonRsAdz4h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOZ68nqSHM0g",
        "outputId": "691578f0-8d6f-4f94-e7cb-631ccc384d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import The Libraries"
      ],
      "metadata": {
        "id": "VtkqJiD7eBrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "metadata": {
        "id": "w4JHZMgkH-VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set The Dataset Path"
      ],
      "metadata": {
        "id": "qUbX5wISeIPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Updated path based on your screenshot\n",
        "dataset_path = '/content/drive/MyDrive/project/Brain_Tumor_Data/Brain/'\n",
        "\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"âœ… Correct Path Found!\")\n",
        "\n",
        "    # 20% validation split\n",
        "    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "    train_data = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='training'\n",
        "    )\n",
        "\n",
        "    val_data = datagen.flow_from_directory(\n",
        "        dataset_path,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary',\n",
        "        subset='validation'\n",
        "    )\n",
        "else:\n",
        "    print(\"âŒ Path still not found. Please check spelling!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouiaxcjrOhF2",
        "outputId": "c42b247b-bdde-4cd1-b6d6-56e786122992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Correct Path Found!\n",
            "Found 203 images belonging to 2 classes.\n",
            "Found 50 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Brain Tumor"
      ],
      "metadata": {
        "id": "SOLoFIWkeXlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Setup MobileNetV2 (Transfer Learning)\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False # Freeze pre-trained layers\n",
        "\n",
        "# 2. Add custom layers\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Binary: yes or no\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train for 20 Epochs\n",
        "print(\"ğŸš€ Starting Training...\")\n",
        "model.fit(train_data, epochs=20, validation_data=val_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSUXTEeIOnoR",
        "outputId": "fa1f0910-3315-4cb8-aa8a-110f9aa0d605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting Training...\n",
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6042 - loss: 0.6281 - val_accuracy: 0.8400 - val_loss: 0.3390\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8224 - loss: 0.3836 - val_accuracy: 0.9200 - val_loss: 0.2371\n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8899 - loss: 0.2644 - val_accuracy: 0.9400 - val_loss: 0.1806\n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.8888 - loss: 0.2538 - val_accuracy: 0.9600 - val_loss: 0.1828\n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9263 - loss: 0.1836 - val_accuracy: 0.9400 - val_loss: 0.1771\n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9281 - loss: 0.1739 - val_accuracy: 0.9400 - val_loss: 0.1671\n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9361 - loss: 0.1342 - val_accuracy: 0.9600 - val_loss: 0.1544\n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9761 - loss: 0.0975 - val_accuracy: 0.9600 - val_loss: 0.1538\n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.9679 - loss: 0.0911 - val_accuracy: 0.9200 - val_loss: 0.1929\n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9827 - loss: 0.0646 - val_accuracy: 0.9400 - val_loss: 0.1543\n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9752 - loss: 0.0733 - val_accuracy: 0.9200 - val_loss: 0.1887\n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9918 - loss: 0.0565 - val_accuracy: 0.9400 - val_loss: 0.1855\n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.9728 - loss: 0.0640 - val_accuracy: 0.9200 - val_loss: 0.2098\n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9828 - loss: 0.0430 - val_accuracy: 0.9000 - val_loss: 0.1995\n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.9878 - loss: 0.0625 - val_accuracy: 0.9200 - val_loss: 0.1827\n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9988 - loss: 0.0329 - val_accuracy: 0.9400 - val_loss: 0.1731\n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9554 - loss: 0.0714 - val_accuracy: 0.9400 - val_loss: 0.2026\n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9776 - loss: 0.0708 - val_accuracy: 0.9400 - val_loss: 0.1721\n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9914 - loss: 0.0445 - val_accuracy: 0.9200 - val_loss: 0.1748\n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9838 - loss: 0.0468 - val_accuracy: 0.9200 - val_loss: 0.1803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ce9003f74a0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save The Brain Tumor Model (.h5 file)"
      ],
      "metadata": {
        "id": "ITs1PomYelW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to your models folder\n",
        "save_path = '/content/drive/MyDrive/project/models/brain_tumor_model.h5'\n",
        "\n",
        "# Save the model\n",
        "model.save(save_path)\n",
        "print(f\"âœ… Brain Tumor model saved successfully to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMhQurN3RYMz",
        "outputId": "5cb145bb-207f-434d-db21-17ee9a4e17b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Brain Tumor model saved successfully to: /content/drive/MyDrive/project/models/brain_tumor_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set The Dataset Path For Skin Cancer"
      ],
      "metadata": {
        "id": "VxUSTvLle4EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Base directory\n",
        "base_dir = '/content/drive/MyDrive/project/Skin_Cancer_Data/'\n",
        "\n",
        "# This code finds that long folder name automatically\n",
        "subfolders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
        "long_folder_name = subfolders[0] # Picks the first folder it finds\n",
        "\n",
        "# Correct path points to TRAIN\n",
        "skin_dataset_path = os.path.join(base_dir, long_folder_name, 'Train')\n",
        "\n",
        "print(f\"Target Path: {skin_dataset_path}\")\n",
        "\n",
        "if os.path.exists(skin_dataset_path):\n",
        "    print(\"âœ… Path found successfully!\")\n",
        "else:\n",
        "    print(\"âŒ Path still not found. Please use the sidebar to 'Copy Path' of the Train folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwvM4b7DTDfU",
        "outputId": "d49437c1-d864-481f-8981-575cacef288f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target Path: /content/drive/MyDrive/project/Skin_Cancer_Data/Skin cancer ISIC The International Skin Imaging Collaboration/Train\n",
            "âœ… Path found successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find The Classes"
      ],
      "metadata": {
        "id": "dUHE41RhfBCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Point to the path found in your previous step\n",
        "skin_dataset_path = '/content/drive/MyDrive/project/Skin_Cancer_Data/Skin cancer ISIC The International Skin Imaging Collaboration/Train'\n",
        "\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Loading Training Data\n",
        "train_data_skin = datagen.flow_from_directory(\n",
        "    skin_dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical', # Use categorical because skin data has multiple classes\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Loading Validation Data\n",
        "val_data_skin = datagen.flow_from_directory(\n",
        "    skin_dataset_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "print(f\"âœ… Loaded {train_data_skin.num_classes} categories of skin diseases.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl8HSpFVTI7y",
        "outputId": "7d21fcf2-9762-41a9-c0d5-e30a31814736"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1796 images belonging to 9 classes.\n",
            "Found 444 images belonging to 9 classes.\n",
            "âœ… Loaded 9 categories of skin diseases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train The Skin Cancer Model"
      ],
      "metadata": {
        "id": "o3RIaXzyfV_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Setup MobileNetV2 (Frozen Base)\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# 2. Add classification layers for 9 classes\n",
        "skin_model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(9, activation='softmax') # Matching your 9 categories\n",
        "])\n",
        "\n",
        "skin_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 3. Train for 20 Epochs\n",
        "print(\"ğŸš€ Starting Skin Cancer Training...\")\n",
        "history = skin_model.fit(\n",
        "    train_data_skin,\n",
        "    epochs=20,\n",
        "    validation_data=val_data_skin\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28s2pGDdTTcl",
        "outputId": "54a8c24f-5384-48a0-f16d-9ae6d55db151"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting Skin Cancer Training...\n",
            "Epoch 1/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 2s/step - accuracy: 0.2583 - loss: 2.0883 - val_accuracy: 0.3739 - val_loss: 1.6424\n",
            "Epoch 2/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.4978 - loss: 1.5190 - val_accuracy: 0.4347 - val_loss: 1.5381\n",
            "Epoch 3/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.5323 - loss: 1.3264 - val_accuracy: 0.4775 - val_loss: 1.4761\n",
            "Epoch 4/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.5707 - loss: 1.2474 - val_accuracy: 0.4752 - val_loss: 1.4953\n",
            "Epoch 5/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 3s/step - accuracy: 0.6186 - loss: 1.1350 - val_accuracy: 0.4685 - val_loss: 1.4554\n",
            "Epoch 6/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.6014 - loss: 1.1281 - val_accuracy: 0.4707 - val_loss: 1.4934\n",
            "Epoch 7/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.6122 - loss: 1.0735 - val_accuracy: 0.5023 - val_loss: 1.4313\n",
            "Epoch 8/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2s/step - accuracy: 0.6383 - loss: 1.0045 - val_accuracy: 0.4595 - val_loss: 1.6301\n",
            "Epoch 9/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.6774 - loss: 0.9606 - val_accuracy: 0.4932 - val_loss: 1.4665\n",
            "Epoch 10/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.6929 - loss: 0.8895 - val_accuracy: 0.5068 - val_loss: 1.4880\n",
            "Epoch 11/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 2s/step - accuracy: 0.6705 - loss: 0.9031 - val_accuracy: 0.5135 - val_loss: 1.4720\n",
            "Epoch 12/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 2s/step - accuracy: 0.6962 - loss: 0.8339 - val_accuracy: 0.4955 - val_loss: 1.4458\n",
            "Epoch 13/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2s/step - accuracy: 0.7023 - loss: 0.8200 - val_accuracy: 0.4730 - val_loss: 1.5295\n",
            "Epoch 14/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.7389 - loss: 0.7501 - val_accuracy: 0.5045 - val_loss: 1.4613\n",
            "Epoch 15/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 2s/step - accuracy: 0.7326 - loss: 0.7347 - val_accuracy: 0.4887 - val_loss: 1.4985\n",
            "Epoch 16/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 2s/step - accuracy: 0.7427 - loss: 0.7202 - val_accuracy: 0.5068 - val_loss: 1.5507\n",
            "Epoch 17/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 2s/step - accuracy: 0.7703 - loss: 0.6584 - val_accuracy: 0.5158 - val_loss: 1.5650\n",
            "Epoch 18/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 2s/step - accuracy: 0.7469 - loss: 0.6805 - val_accuracy: 0.4887 - val_loss: 1.5912\n",
            "Epoch 19/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 2s/step - accuracy: 0.7616 - loss: 0.6610 - val_accuracy: 0.4865 - val_loss: 1.5787\n",
            "Epoch 20/20\n",
            "\u001b[1m57/57\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 2s/step - accuracy: 0.7690 - loss: 0.6242 - val_accuracy: 0.4865 - val_loss: 1.6994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save The Model (H5 file)"
      ],
      "metadata": {
        "id": "jhmW73FdfgH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save with a specific name for skin cancer\n",
        "save_path = '/content/drive/MyDrive/project/models/skin_cancer_model.h5'\n",
        "skin_model.save(save_path)\n",
        "print(f\"âœ… Skin model saved at: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLrcP7kZprby",
        "outputId": "6a6c7133-6132-460a-ef73-389f834b8c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Skin model saved at: /content/drive/MyDrive/project/models/skin_cancer_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Exact path from your screenshots\n",
        "base_path = '/content/drive/MyDrive/project/Pneumonia_Data/chest_xray/'\n",
        "train_path = os.path.join(base_path, 'train')\n",
        "val_path = os.path.join(base_path, 'val')\n",
        "\n",
        "# Rescale images\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load Training Data\n",
        "train_data_chest = datagen.flow_from_directory(\n",
        "    train_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary' # Usually Pneumonia vs Normal\n",
        ")\n",
        "\n",
        "# Load Validation Data\n",
        "val_data_chest = datagen.flow_from_directory(\n",
        "    val_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "print(f\"âœ… Loaded {train_data_chest.num_classes} classes for Chest X-Ray.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_WsOa-tu96",
        "outputId": "81038491-5cd2-4a4b-936c-5f5165fd4f48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5219 images belonging to 2 classes.\n",
            "Found 16 images belonging to 2 classes.\n",
            "âœ… Loaded 2 classes for Chest X-Ray.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# 1. Base Model (Frozen for Transfer Learning)\n",
        "base_model = MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = False\n",
        "\n",
        "# 2. Add Classification Head\n",
        "chest_model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid') # Binary: Pneumonia or Normal\n",
        "])\n",
        "\n",
        "chest_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 3. Train for 20 Epochs\n",
        "print(\"ğŸš€ Starting Chest X-Ray Training...\")\n",
        "chest_model.fit(\n",
        "    train_data_chest,\n",
        "    epochs=20,\n",
        "    validation_data=val_data_chest\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqP1K5SwuIsr",
        "outputId": "8d4771ab-29d8-45c9-afe0-ffa0adb3a773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ Starting Chest X-Ray Training...\n",
            "Epoch 1/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 3s/step - accuracy: 0.9179 - loss: 0.2071 - val_accuracy: 0.8125 - val_loss: 0.5559\n",
            "Epoch 2/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.9639 - loss: 0.1026 - val_accuracy: 0.8125 - val_loss: 0.5031\n",
            "Epoch 3/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 2s/step - accuracy: 0.9643 - loss: 0.0912 - val_accuracy: 0.8750 - val_loss: 0.1649\n",
            "Epoch 4/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 2s/step - accuracy: 0.9699 - loss: 0.0860 - val_accuracy: 0.8125 - val_loss: 0.5170\n",
            "Epoch 5/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 2s/step - accuracy: 0.9648 - loss: 0.0843 - val_accuracy: 0.8750 - val_loss: 0.1912\n",
            "Epoch 6/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 2s/step - accuracy: 0.9695 - loss: 0.0825 - val_accuracy: 0.8750 - val_loss: 0.3084\n",
            "Epoch 7/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.9720 - loss: 0.0741 - val_accuracy: 0.8125 - val_loss: 0.3780\n",
            "Epoch 8/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 2s/step - accuracy: 0.9758 - loss: 0.0634 - val_accuracy: 0.8750 - val_loss: 0.2995\n",
            "Epoch 9/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 2s/step - accuracy: 0.9802 - loss: 0.0576 - val_accuracy: 0.9375 - val_loss: 0.1151\n",
            "Epoch 10/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 2s/step - accuracy: 0.9742 - loss: 0.0673 - val_accuracy: 0.9375 - val_loss: 0.1470\n",
            "Epoch 11/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.9791 - loss: 0.0550 - val_accuracy: 0.8750 - val_loss: 0.3001\n",
            "Epoch 12/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.9808 - loss: 0.0547 - val_accuracy: 0.8750 - val_loss: 0.2397\n",
            "Epoch 13/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.9868 - loss: 0.0370 - val_accuracy: 0.7500 - val_loss: 0.4871\n",
            "Epoch 14/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 2s/step - accuracy: 0.9820 - loss: 0.0484 - val_accuracy: 0.9375 - val_loss: 0.1786\n",
            "Epoch 15/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 2s/step - accuracy: 0.9841 - loss: 0.0448 - val_accuracy: 0.8750 - val_loss: 0.2571\n",
            "Epoch 16/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 2s/step - accuracy: 0.9814 - loss: 0.0427 - val_accuracy: 0.8750 - val_loss: 0.2693\n",
            "Epoch 17/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 2s/step - accuracy: 0.9863 - loss: 0.0425 - val_accuracy: 0.8750 - val_loss: 0.3022\n",
            "Epoch 18/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 2s/step - accuracy: 0.9763 - loss: 0.0574 - val_accuracy: 0.8750 - val_loss: 0.2279\n",
            "Epoch 19/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 2s/step - accuracy: 0.9855 - loss: 0.0355 - val_accuracy: 0.8750 - val_loss: 0.2910\n",
            "Epoch 20/20\n",
            "\u001b[1m164/164\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 2s/step - accuracy: 0.9765 - loss: 0.0627 - val_accuracy: 1.0000 - val_loss: 0.0993\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ce8e0a55910>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chest_save_path = '/content/drive/MyDrive/project/models/chest_model.h5'\n",
        "chest_model.save(chest_save_path)\n",
        "print(f\"âœ… Chest X-Ray model saved at: {chest_save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvRPm3vQHB1O",
        "outputId": "7d840189-e7b0-4320-91a9-303d763c9e9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Chest X-Ray model saved at: /content/drive/MyDrive/project/models/chest_model.h5\n"
          ]
        }
      ]
    }
  ]
}